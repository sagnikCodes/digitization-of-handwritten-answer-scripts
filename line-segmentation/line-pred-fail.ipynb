{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7986946,"sourceType":"datasetVersion","datasetId":4701517}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Utility Libraries\nimport numpy as np\nimport pandas as pd\nimport sys\nimport time\nimport random\nfrom scipy import linalg\nimport cv2\nfrom PIL import Image\nfrom PIL.Image import fromarray\nimport os\n\n# Pytorch relevant librariesa\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch import cat\nfrom torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.models import inception_v3\nfrom torch.utils.data import random_split\n\n# Plotting Libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom sklearn.manifold import TSNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-11T19:33:00.895010Z","iopub.execute_input":"2024-04-11T19:33:00.895848Z","iopub.status.idle":"2024-04-11T19:33:09.574118Z","shell.execute_reply.started":"2024-04-11T19:33:00.895813Z","shell.execute_reply":"2024-04-11T19:33:09.573330Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.575543Z","iopub.execute_input":"2024-04-11T19:33:09.575968Z","iopub.status.idle":"2024-04-11T19:33:09.580159Z","shell.execute_reply.started":"2024-04-11T19:33:09.575943Z","shell.execute_reply":"2024-04-11T19:33:09.579152Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/iam-lines/IAM/gt_test.txt') as f:\n    contents = f.readlines()\n\nlines = [line.strip() for line in contents]","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.581198Z","iopub.execute_input":"2024-04-11T19:33:09.581430Z","iopub.status.idle":"2024-04-11T19:33:09.603857Z","shell.execute_reply.started":"2024-04-11T19:33:09.581409Z","shell.execute_reply":"2024-04-11T19:33:09.602922Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"file_names = []\ntexts = []\n\nfor line in lines:\n    file_name = line.split('\\t')[0]\n    text = line.split('\\t')[-1]\n    \n    file_names.append(file_name)\n    texts.append(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.606431Z","iopub.execute_input":"2024-04-11T19:33:09.606986Z","iopub.status.idle":"2024-04-11T19:33:09.614478Z","shell.execute_reply.started":"2024-04-11T19:33:09.606961Z","shell.execute_reply":"2024-04-11T19:33:09.613609Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"lines_data = pd.DataFrame()\nlines_data['file_name'] = file_names\nlines_data['text'] = texts","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.615482Z","iopub.execute_input":"2024-04-11T19:33:09.615762Z","iopub.status.idle":"2024-04-11T19:33:09.633739Z","shell.execute_reply.started":"2024-04-11T19:33:09.615740Z","shell.execute_reply":"2024-04-11T19:33:09.632942Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"lines_data","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.634858Z","iopub.execute_input":"2024-04-11T19:33:09.635143Z","iopub.status.idle":"2024-04-11T19:33:09.650467Z","shell.execute_reply.started":"2024-04-11T19:33:09.635119Z","shell.execute_reply":"2024-04-11T19:33:09.649687Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           file_name                                               text\n0     c04-110-00.jpg  Become a success with a disc and hey presto ! ...\n1     c04-110-01.jpg  assuredness \" Bella Bella Marie \" ( Parlophone...\n2     c04-110-02.jpg  I don't think he will storm the charts with th...\n3     c04-110-03.jpg  CHRIS CHARLES , 39 , who lives in Stockton-on-...\n4     c04-116-00.jpg  He is also a director of a couple of garages ....\n...              ...                                                ...\n2910  r03-053-04.jpg           just dusty-grey but muddy , slimy even .\n2911  r03-053-05.jpg      His digressions too , seemed to have no other\n2912  r03-053-06.jpg           purpose than the throwing of dust in his\n2913  r03-053-07.jpg     client's eyes , the dust of fake security , of\n2914  r03-053-08.jpg           the fake friend of the family , like the\n\n[2915 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c04-110-00.jpg</td>\n      <td>Become a success with a disc and hey presto ! ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c04-110-01.jpg</td>\n      <td>assuredness \" Bella Bella Marie \" ( Parlophone...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c04-110-02.jpg</td>\n      <td>I don't think he will storm the charts with th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c04-110-03.jpg</td>\n      <td>CHRIS CHARLES , 39 , who lives in Stockton-on-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c04-116-00.jpg</td>\n      <td>He is also a director of a couple of garages ....</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2910</th>\n      <td>r03-053-04.jpg</td>\n      <td>just dusty-grey but muddy , slimy even .</td>\n    </tr>\n    <tr>\n      <th>2911</th>\n      <td>r03-053-05.jpg</td>\n      <td>His digressions too , seemed to have no other</td>\n    </tr>\n    <tr>\n      <th>2912</th>\n      <td>r03-053-06.jpg</td>\n      <td>purpose than the throwing of dust in his</td>\n    </tr>\n    <tr>\n      <th>2913</th>\n      <td>r03-053-07.jpg</td>\n      <td>client's eyes , the dust of fake security , of</td>\n    </tr>\n    <tr>\n      <th>2914</th>\n      <td>r03-053-08.jpg</td>\n      <td>the fake friend of the family , like the</td>\n    </tr>\n  </tbody>\n</table>\n<p>2915 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"char_list = \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \" \n\ndef encode_to_labels(text, max_word_length=85):\n    dig_list = []\n    for index in range(max_word_length):\n        char = 79\n        if index < len(text):\n            char = char_list.index(text[index])\n        dig_list.append(char) \n        \n    return dig_list","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.651407Z","iopub.execute_input":"2024-04-11T19:33:09.651688Z","iopub.status.idle":"2024-04-11T19:33:09.657030Z","shell.execute_reply.started":"2024-04-11T19:33:09.651660Z","shell.execute_reply":"2024-04-11T19:33:09.656118Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class IAMDataset(Dataset):\n    def __init__(self, data, root_dir, transform=None):\n        self.data = data\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        file_name = self.data['file_name'][idx]\n        text = self.data['text'][idx]\n\n        file_name = file_name\n        file_path = f\"{self.root_dir}/{file_name}\"\n\n        # Load image\n        try:\n            image = Image.open(file_path).convert(\"RGB\")\n        except:\n            image = torch.zeros((1, 30, 900))\n            label = torch.zeros((85))\n            return image, label\n\n\n        if self.transform:\n            image = self.transform(image)\n            \n        label = torch.tensor(encode_to_labels(text))\n\n        return image, torch.tensor(label)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.658078Z","iopub.execute_input":"2024-04-11T19:33:09.658324Z","iopub.status.idle":"2024-04-11T19:33:09.666660Z","shell.execute_reply.started":"2024-04-11T19:33:09.658303Z","shell.execute_reply":"2024-04-11T19:33:09.665785Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Grayscale(),   \n    transforms.Resize((30, 900)),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.667755Z","iopub.execute_input":"2024-04-11T19:33:09.668043Z","iopub.status.idle":"2024-04-11T19:33:09.679319Z","shell.execute_reply.started":"2024-04-11T19:33:09.668021Z","shell.execute_reply":"2024-04-11T19:33:09.678463Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset = IAMDataset(data=lines_data, root_dir='/kaggle/input/iam-lines/IAM/image', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.682479Z","iopub.execute_input":"2024-04-11T19:33:09.682761Z","iopub.status.idle":"2024-04-11T19:33:09.688982Z","shell.execute_reply.started":"2024-04-11T19:33:09.682739Z","shell.execute_reply":"2024-04-11T19:33:09.688117Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_size = 1\n\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.689961Z","iopub.execute_input":"2024-04-11T19:33:09.690275Z","iopub.status.idle":"2024-04-11T19:33:09.700075Z","shell.execute_reply.started":"2024-04-11T19:33:09.690247Z","shell.execute_reply":"2024-04-11T19:33:09.699260Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def visualize_image(dataloader):\n    for image, labels in dataloader:\n        break\n        \n    image = image[0]  # first image\n    plt.figure(figsize=(4, 16))\n    plt.imshow(image.permute(1, 2, 0), cmap='gray')\n    label = ''.join([char_list[index] for index in labels[0] if index != 79])\n    print(label)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.701128Z","iopub.execute_input":"2024-04-11T19:33:09.701383Z","iopub.status.idle":"2024-04-11T19:33:09.709868Z","shell.execute_reply.started":"2024-04-11T19:33:09.701362Z","shell.execute_reply":"2024-04-11T19:33:09.708959Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"visualize_image(train_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.710895Z","iopub.execute_input":"2024-04-11T19:33:09.711151Z","iopub.status.idle":"2024-04-11T19:33:09.864075Z","shell.execute_reply.started":"2024-04-11T19:33:09.711129Z","shell.execute_reply":"2024-04-11T19:33:09.862663Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Gay , a little puzzled , went through\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x1600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"class FeatureExtractor(nn.Module):\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n\n        # Load pre-trained ResNet34 model\n        self.resnet = models.resnet34(pretrained=True)\n\n        # Modify the first convolutional layer to accommodate grayscale images\n        conv1_weight = self.resnet.conv1.weight.data\n        conv1_weight = conv1_weight.mean(dim=1, keepdim=True)\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.resnet.conv1.weight.data = conv1_weight\n\n        # Remove the last fully connected layer of ResNet34\n        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n\n        # Freeze the ResNet layers so they won't be trained\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        # Forward pass through ResNet layers\n        x = self.resnet(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:09.866151Z","iopub.execute_input":"2024-04-11T19:33:09.866803Z","iopub.status.idle":"2024-04-11T19:33:09.880489Z","shell.execute_reply.started":"2024-04-11T19:33:09.866758Z","shell.execute_reply":"2024-04-11T19:33:09.879096Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers):\n        super(Encoder, self).__init__()\n        \n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        \n        self.gru = nn.GRU(self.input_dim, self.hidden_dim, num_layers=self.num_layers)\n              \n    def forward(self, x):\n        outputs, hidden = self.gru(x)\n        return outputs, hidden","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:27.976059Z","iopub.execute_input":"2024-04-11T19:33:27.976794Z","iopub.status.idle":"2024-04-11T19:33:27.982862Z","shell.execute_reply.started":"2024-04-11T19:33:27.976765Z","shell.execute_reply":"2024-04-11T19:33:27.981870Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, input_dim, output_dim, hidden_dim, num_layers):\n        super(Decoder, self).__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.output_dim = output_dim\n        self.num_layers = num_layers\n        \n        self.gru = nn.GRU(input_dim, self.hidden_dim, num_layers=self.num_layers)\n        self.out = nn.Linear(self.hidden_dim, output_dim)\n\n    def forward(self, x, hidden):\n        x = x.view(1, -1)\n        output, hidden = self.gru(x, hidden)   \n        prediction = self.out(output[0])\n\n        return prediction, hidden","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:28.275233Z","iopub.execute_input":"2024-04-11T19:33:28.275521Z","iopub.status.idle":"2024-04-11T19:33:28.282197Z","shell.execute_reply.started":"2024-04-11T19:33:28.275495Z","shell.execute_reply":"2024-04-11T19:33:28.281304Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, enc_input_dim, dec_input_dim, hidden_dim, target_length=100, num_chars=80):\n        super(Seq2Seq, self).__init__()\n        self.target_length = target_length\n        self.num_chars = num_chars\n        \n        self.encoder = Encoder(\n            input_dim=enc_input_dim,\n            hidden_dim=hidden_dim,\n            num_layers=1\n        ).to(device)\n        \n        self.decoder = Decoder(\n            input_dim=dec_input_dim,\n            output_dim=dec_input_dim,\n            hidden_dim=hidden_dim,\n            num_layers=1\n        ).to(device)\n        \n    def forward(self, features):\n        seq_length = features.shape[0]\n        \n        for i in range(seq_length):\n            enc_output, enc_hidden = self.encoder(features[i])\n            \n        outputs = torch.zeros(self.target_length, self.num_chars).to(device)\n        \n        dec_hidden = enc_hidden\n        dec_input = torch.zeros(1, num_chars).to(device)\n\n        for i in range(self.target_length):\n            decoder_output, dec_hidden = self.decoder(dec_input, dec_hidden)\n            outputs[i] = decoder_output\n            dec_input = decoder_output\n            \n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:29.029585Z","iopub.execute_input":"2024-04-11T19:33:29.029949Z","iopub.status.idle":"2024-04-11T19:33:29.039155Z","shell.execute_reply.started":"2024-04-11T19:33:29.029921Z","shell.execute_reply":"2024-04-11T19:33:29.038198Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class HandwrittenLineRecognizer(nn.Module):\n    def __init__(self, feature_extractor, seq2seq):\n        super(HandwrittenLineRecognizer, self).__init__()\n        self.feature_extractor = feature_extractor.to(device)\n        self.seq2seq = seq2seq.to(device)\n        \n    def forward(self, line):\n        features = self.feature_extractor(line)\n        features = features.squeeze(2).permute(2, 0, 1)\n        output = self.seq2seq(features).unsqueeze(0)\n        output = output.permute(0, 2, 1)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:29.692746Z","iopub.execute_input":"2024-04-11T19:33:29.693053Z","iopub.status.idle":"2024-04-11T19:33:29.699261Z","shell.execute_reply.started":"2024-04-11T19:33:29.693027Z","shell.execute_reply":"2024-04-11T19:33:29.698282Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:48.314954Z","iopub.execute_input":"2024-04-11T19:33:48.315737Z","iopub.status.idle":"2024-04-11T19:33:48.347998Z","shell.execute_reply.started":"2024-04-11T19:33:48.315702Z","shell.execute_reply":"2024-04-11T19:33:48.346682Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"enc_input_dim = 512\ndec_input_dim = 80\nhidden_dim = 256\ntarget_length = 85\nnum_chars = 80\n\nfeature_extractor = FeatureExtractor()\nseq2seq = Seq2Seq(enc_input_dim, dec_input_dim, hidden_dim, target_length, num_chars)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:33:49.526768Z","iopub.execute_input":"2024-04-11T19:33:49.527100Z","iopub.status.idle":"2024-04-11T19:33:50.297875Z","shell.execute_reply.started":"2024-04-11T19:33:49.527071Z","shell.execute_reply":"2024-04-11T19:33:50.296917Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n        self.pool4 = nn.MaxPool2d(kernel_size=(2, 1))\n        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n        self.batch_norm5 = nn.BatchNorm2d(512)\n        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n        self.batch_norm6 = nn.BatchNorm2d(512)\n        self.pool6 = nn.MaxPool2d(kernel_size=(2, 2))\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool2(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.pool4(x)\n        x = F.relu(self.conv5(x))\n        x = self.batch_norm5(x)\n        x = F.relu(self.conv6(x))\n        x = self.batch_norm6(x)\n        x = self.pool6(x)\n        x = x.squeeze(2)  # Squeeze the height dimension\n        x = x.permute(2, 0, 1)  # Reshape for RNN input\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:34:34.266551Z","iopub.execute_input":"2024-04-11T19:34:34.266932Z","iopub.status.idle":"2024-04-11T19:34:34.278433Z","shell.execute_reply.started":"2024-04-11T19:34:34.266905Z","shell.execute_reply":"2024-04-11T19:34:34.277507Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, bidirectional=True, dropout=0.2)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers * 2, x.size(1), self.hidden_size).to(device)\n        c0 = torch.zeros(self.num_layers * 2, x.size(1), self.hidden_size).to(device)\n        output, _ = self.lstm(x, (h0, c0))\n        output = self.fc(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:34:34.460979Z","iopub.execute_input":"2024-04-11T19:34:34.461267Z","iopub.status.idle":"2024-04-11T19:34:34.468345Z","shell.execute_reply.started":"2024-04-11T19:34:34.461243Z","shell.execute_reply":"2024-04-11T19:34:34.467439Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class HandwritingRecognitionModel(nn.Module):\n    def __init__(self, num_classes):\n        super(HandwritingRecognitionModel, self).__init__()\n        self.cnn = CNN()\n        self.rnn = RNN(512, 256, 2, num_classes)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        x = self.rnn(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:37:44.121282Z","iopub.execute_input":"2024-04-11T19:37:44.121654Z","iopub.status.idle":"2024-04-11T19:37:44.127531Z","shell.execute_reply.started":"2024-04-11T19:37:44.121616Z","shell.execute_reply":"2024-04-11T19:37:44.126535Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"num_classes = 80  # 78 characters + 1 for blank\nnum_epochs = 10\nmodel = HandwritingRecognitionModel(num_classes)\n\n# Loss function\ncriterion = nn.CTCLoss(blank=79, zero_infinity=True)\n\n# Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:37:44.377447Z","iopub.execute_input":"2024-04-11T19:37:44.377742Z","iopub.status.idle":"2024-04-11T19:37:44.446191Z","shell.execute_reply.started":"2024-04-11T19:37:44.377718Z","shell.execute_reply":"2024-04-11T19:37:44.445501Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"T = 112\nC = 80\nS = 85\nS_min = 84\n\nloss_trajectory = []\nmodel = HandwritingRecognitionModel(num_classes).to(device)\nfor epoch in range(10):\n    losses = []\n    num_batches = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        N = images.shape[0]\n        optimizer.zero_grad()\n        outputs = model(images)\n        input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n        target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n        loss = criterion(outputs, labels, input_lengths, target_lengths)\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n        torch.cuda.empty_cache()\n        num_batches += 1\n        \n        if num_batches % 500 == 0:\n            print(f'Epoch {epoch + 1}, Batch : {num_batches}, Loss : {loss.item()}')\n        loss_trajectory.append(np.round(np.mean(losses), 3))\n    print(f\"For Epoch {epoch + 1} : Loss : {np.round(np.mean(losses), 3)}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:38:57.201282Z","iopub.execute_input":"2024-04-11T19:38:57.201928Z","iopub.status.idle":"2024-04-11T19:51:31.912186Z","shell.execute_reply.started":"2024-04-11T19:38:57.201892Z","shell.execute_reply":"2024-04-11T19:51:31.911276Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Epoch 1, Batch : 500, Loss : -0.05242469161748886\nEpoch 1, Batch : 1000, Loss : 0.0\nEpoch 1, Batch : 1500, Loss : 0.050859421491622925\nEpoch 1, Batch : 2000, Loss : 0.0\nEpoch 1, Batch : 2500, Loss : 0.0\nFor Epoch 1 : Loss : -0.019\n\nEpoch 2, Batch : 500, Loss : 0.0\nEpoch 2, Batch : 1000, Loss : 0.0\nEpoch 2, Batch : 1500, Loss : 0.0\nEpoch 2, Batch : 2000, Loss : 0.0\nEpoch 2, Batch : 2500, Loss : 0.0\nFor Epoch 2 : Loss : -0.019\n\nEpoch 3, Batch : 500, Loss : 0.0\nEpoch 3, Batch : 1000, Loss : 0.0\nEpoch 3, Batch : 1500, Loss : 0.0\nEpoch 3, Batch : 2000, Loss : 0.0\nEpoch 3, Batch : 2500, Loss : 0.0\nFor Epoch 3 : Loss : -0.019\n\nEpoch 4, Batch : 500, Loss : 0.0\nEpoch 4, Batch : 1000, Loss : 0.0\nEpoch 4, Batch : 1500, Loss : -0.3164207935333252\nEpoch 4, Batch : 2000, Loss : 0.0\nEpoch 4, Batch : 2500, Loss : 0.0\nFor Epoch 4 : Loss : -0.019\n\nEpoch 5, Batch : 500, Loss : 0.0\nEpoch 5, Batch : 1000, Loss : 0.0036552411038428545\nEpoch 5, Batch : 1500, Loss : 0.0\nEpoch 5, Batch : 2000, Loss : 0.0\nEpoch 5, Batch : 2500, Loss : 0.0\nFor Epoch 5 : Loss : -0.019\n\nEpoch 6, Batch : 500, Loss : 0.0\nEpoch 6, Batch : 1000, Loss : 0.0\nEpoch 6, Batch : 1500, Loss : 0.0\nEpoch 6, Batch : 2000, Loss : 0.0\nEpoch 6, Batch : 2500, Loss : 0.0\nFor Epoch 6 : Loss : -0.019\n\nEpoch 7, Batch : 500, Loss : 0.0\nEpoch 7, Batch : 1000, Loss : 0.0\nEpoch 7, Batch : 1500, Loss : 0.0\nEpoch 7, Batch : 2000, Loss : 0.0\nEpoch 7, Batch : 2500, Loss : 0.0\nFor Epoch 7 : Loss : -0.019\n\nEpoch 8, Batch : 500, Loss : 0.0\nEpoch 8, Batch : 1000, Loss : 0.0\nEpoch 8, Batch : 1500, Loss : 0.0\nEpoch 8, Batch : 2000, Loss : 0.0\nEpoch 8, Batch : 2500, Loss : 0.0\nFor Epoch 8 : Loss : -0.019\n\nEpoch 9, Batch : 500, Loss : 0.0\nEpoch 9, Batch : 1000, Loss : 0.0\nEpoch 9, Batch : 1500, Loss : 0.0\nEpoch 9, Batch : 2000, Loss : 0.0\nEpoch 9, Batch : 2500, Loss : 0.0\nFor Epoch 9 : Loss : -0.019\n\nEpoch 10, Batch : 500, Loss : 0.053567271679639816\nEpoch 10, Batch : 1000, Loss : 0.0\nEpoch 10, Batch : 1500, Loss : 0.0\nEpoch 10, Batch : 2000, Loss : 0.0\nEpoch 10, Batch : 2500, Loss : 0.0\nFor Epoch 10 : Loss : -0.019\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_text(sequence):\n    text = \"\"\n    for i in sequence:\n        i = i.item()\n        if i != 79:\n            text += char_list[i]\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:51:43.809452Z","iopub.execute_input":"2024-04-11T19:51:43.809820Z","iopub.status.idle":"2024-04-11T19:51:43.814911Z","shell.execute_reply.started":"2024-04-11T19:51:43.809791Z","shell.execute_reply":"2024-04-11T19:51:43.813944Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def ctc_greedy_decode_batch(logits, blank_index=0):\n    \"\"\"\n    Greedy decoding for CTC output for a batch of sequences.\n    \n    Args:\n    logits (np.array): Logits from the model, shape (T, batch_size, C),\n                       where T is the sequence length, batch_size is the\n                       batch size, and C is the number of characters.\n    blank_index (int): Index of the blank symbol.\n    \n    Returns:\n    decoded_sequences (list of lists): Decoded sequences of characters for each batch element.\n    \"\"\"\n    T, batch_size, C = logits.shape\n    decoded_sequences = []\n\n    for b in range(batch_size):\n        # Get the logits for the current batch element\n        batch_logits = logits[:, b, :]\n        \n        # Get the index with maximum probability for each timestep\n        best_path = np.argmax(batch_logits, axis=1)\n        \n        # Collapse consecutive duplicates and remove blank symbols\n        decoded_sequence = [best_path[0]]\n        for i in range(1, len(best_path)):\n            if best_path[i] != blank_index and best_path[i] != best_path[i - 1]:\n                decoded_sequence.append(best_path[i])\n        \n        decoded_sequences.append(decoded_sequence)\n\n    output_text = []\n    for sequence in decoded_sequences:\n        output_text.append(get_text(sequence))\n    \n    return output_text","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:51:46.912252Z","iopub.execute_input":"2024-04-11T19:51:46.912578Z","iopub.status.idle":"2024-04-11T19:51:46.921160Z","shell.execute_reply.started":"2024-04-11T19:51:46.912554Z","shell.execute_reply":"2024-04-11T19:51:46.920127Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"decoded_sequences = ctc_greedy_decode_batch(outputs.detach().cpu())","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:51:48.412334Z","iopub.execute_input":"2024-04-11T19:51:48.412672Z","iopub.status.idle":"2024-04-11T19:51:48.427858Z","shell.execute_reply.started":"2024-04-11T19:51:48.412647Z","shell.execute_reply":"2024-04-11T19:51:48.426991Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"print(decoded_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:51:54.470500Z","iopub.execute_input":"2024-04-11T19:51:54.471367Z","iopub.status.idle":"2024-04-11T19:51:54.475908Z","shell.execute_reply.started":"2024-04-11T19:51:54.471333Z","shell.execute_reply":"2024-04-11T19:51:54.474921Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"['fMfMblWMlwlwbfblkfkbEbflflfkbMlbl6bEfbfbMlMlbklfbfbfMfEkwW']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}